%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{structure}

\usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry} % Document margins
\usepackage{xcolor}
\usepackage{fontspec}
\setmainfont[]{Roboto}

\name{Tom Pollak}

\begin{document}

\parbox{0.5\textwidth}{
    {\namesize\textbf{Tom Pollak}} \\[6pt]
    Bristol, UK\\
    \href{mailto:tompollak1000@gmail.com}{tompollak1000@gmail.com}
}
\hfill
\parbox{0.5\textwidth}{
    \vspace*{10pt}

    \begin{flushright}

        \href{https://github.com/tom-pollak}{github.com/tom-pollak} \\
        \href{https://tom-pollak.github.io}{tom-pollak.github.io} \\
        (+44) 77400 54268
    \end{flushright}

}

\smallskip
\hrule
\smallskip

%----------------------------------------------------------------------------------------
%	EXPERIENCE
%----------------------------------------------------------------------------------------

\begin{rSection}{Experience \& Education}
    \begin{rSubsection}{Graphcore}{April 2025 -- Present}{Machine Learning Engineer -- Applied AI}{Bristol, UK}{}{}
    \item At Graphcore we are focused on building next-generation AI accelerators, and developing the open-source ecosystem to allow for more heterogeneous compute.

    \item Contributing to open-source ML infrastructure: Fixed a PyTorch pipeline parallelism deadlock bug when using Gloo that affected distributed training ({\color{blue}\href{https://github.com/pytorch/pytorch/pull/152938}{\#152938}}).

    \item Developing mixed-precision pre-training infrastructure. I'm currently working on an experiment targeting a 1B model with up to 1T tokens.
    \end{rSubsection}

    \begin{rSubsection}{Cisco}{June 2023 -- April 2025}{Machine Learning Engineer -- Camera Intelligence Team}{London / Remote, UK}{}{}
        \item Developed computer vision models and pipeline, serving over 4 million networks globally.

        \item Designed and implemented high-performance C++ inference engine and firmware for edge devices (10K+ LOC).

        \item Built distributed k-NN search system across mesh network of cameras, enabling real-time search \& retrieval that scales to thousands of devices per network with no hit to the backend.

        \item Technical lead of a team of 6 engineers managing firmware, model training, inference optimization, and architecture; product featured at Cisco Live 2025.

        \item Created multimodal dataset (>200K objects with a mix of synthetic and human labelled annotations) and fine-tuned CLIP-based models for zero-shot object retrieval.
    \end{rSubsection}

\end{rSection}


\begin{rSubsectionNoList}{University of York}{June 2023}{
        BEng. Computer Science -- First Class with Honours
    }{}{}
\end{rSubsectionNoList}


%----------------------------------------------------------------------------------------
%	PROJECTS
%----------------------------------------------------------------------------------------

\begin{rSection}{Projects}

    \begin{rSubsection}{Structured Generation for LLMs}{March 2025}{}{}{https://github.com/tom-pollak/xverify}{}
        \item Developing a library for structured generation and tool use using automatically generated GBNF grammars and Pydantic schema validation for RLVR.
    \end{rSubsection}

    \begin{rSubsection}{Interpretability Research}{August 2024 -- January 2025}{}{}{https://github.com/tom-pollak/interpretability-culture}{}

        \item Investigating features in neural networks trained on ARC-AGI-style 2D grid puzzles

        \item Trained sparse autoencoders (SAEs), discovering task-specific feature in the models, ablating would degrade performance in a specific task.

        \item Applying \href{https://transformer-circuits.pub/2024/crosscoders/index.html}{Anthropic's Crosscoders} to understand how a model changes throughout training.

        \item Contributed to the \href{https://github.com/jbloomAus/SAELens}{SAELens} library: Optimized activation caching with HuggingFace datasets. (PRs \href{https://github.com/jbloomAus/SAELens/pull/321}{\#321}, \href{https://github.com/jbloomAus/SAELens/pull/367}{\#367})

    \end{rSubsection}

    \begin{rSubsection}{Claudette Pydantic}{July 2024}{}{}{https://github.com/tom-pollak/claudette-pydantic}{}
        \item Extended the \href{https://github.com/AnswerDotAI/claudette}{Claudette} library with structured outputs via tool use -- {\color{blue}\href{https://nbviewer.org/github/tom-pollak/claudette-pydantic/blob/main/nbs/examples/pet_store.ipynb}{Example}}.
    \end{rSubsection}

    \begin{rSubsectionNoList}{NLP Image Retrieval with CLIP \& Faiss}{September 2022 -- June 2023}{}{}{https://tom-pollak.github.io/clip-index}{}
    \end{rSubsectionNoList}

    \begin{rSubsection}{Algorithmic Trading System -- Horse Racing}{December 2020 -- July 2021}{}{}{https://github.com/tom-pollak/each-way-matcher}{}
        \item Developed statistical arbitrage system identifying mispriced "each-way" betting opportunities

        \item Implemented adapted 3-way Kelly Criterion strategy for optimal stake sizing based on calculated conditional place probabilities.

        \item Successful with high ROI, but low volume and I got banned from profitable bookmakers.
    \end{rSubsection}

\end{rSection}

%----------------------------------------------------------------------------------------
%	SKILLS
%----------------------------------------------------------------------------------------

\begin{rSection}{Skills}

    \begin{tabular}{ @{} >{\bfseries}l @{\hspace{6ex}} l }
        Languages & Python, C++, Cuda C, Mojo (learning). \\
        ML        & PyTorch, Triton, Slurm, TorchTitan, vLLM, Modular MAX, Faiss, Huggingface. \\
    \end{tabular}

\end{rSection}

\end{document}
